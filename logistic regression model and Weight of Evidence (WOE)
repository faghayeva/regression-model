# Logistic regression model and Weight of Evidence (WOE)
# Importing packages ----
library(tidyverse)
library(dplyr)
library(rstudioapi)
library(car)
library(inspectdf)
library(caret)
library(glue)
library(highcharter)
library(h2o)
library(mice)
library(scorecard)

# Importing "bank.csv" dataset----
data <- read_delim("C:/Users/aghay/Downloads/bank.csv.csv", delim =";")

# Data cleaning ----

data %>% glimpse()

data %>% inspect_na()

data %>% 
  inspect_na() %>% 
  filter(pcnt<40) %>% 
  pull(col_name) -> variables

data <- data %>% select(all_of(variables))

data$Price <- as.integer(gsub("[^0-9]", "", data$Price))

target <- "Price"

df.num <- data %>% 
  select_if(is.numeric) %>% 
  select(all_of(target),everything())

df.chr <- data %>% 
  mutate_if(is.factor,as.character) %>% 
  select_if(is.character)

data %>% inspect_na()
data[!complete.cases(data),] %>% view()

med_price <- median(data$Price, na.rm=TRUE)
data[is.na(data$Price), "Price"] <- med_price

encoded_data <- data %>% 
  mutate(Installs = as.integer(str_replace_all(Installs, ",", "") == "50+")  # Convert installs to numeric binary
  )

#2 Applying "Weight Of Evidence" ----

# information value

target <- "Installs"


iv <- encoded_data %>%
  iv(y = target) %>%
  as_tibble() %>%
  mutate(info_value = round(info_value, 3)) %>%
  arrange(desc(info_value))

ivars <- iv %>% 
  filter(info_value>0.2) %>% 
  pull(variable)

df.iv <- data %>% select(all_of(target), all_of(ivars))

df.iv %>% dim()

encoded_data <- df.iv %>% 
  mutate(Installs = as.integer(str_replace_all(Installs, ",", "") == "50+")  # Convert installs to numeric binary
  )

# Splitting data ----

set.seed(123)

dt_list <- createDataPartition(encoded_data$Installs, p = 0.8, list = FALSE)
train <- encoded_data[dt_list, ]
test <- encoded_data[-dt_list, ]


# WOE binning ----
bins <- woebin(train, y = "Installs")

train_woe <- woebin_ply(train, bins)
test_woe <- woebin_ply(test, bins)

names <- train_woe %>% 
  names() %>% 
  str_replace_all("_woe", "")

names(train_woe) <- names
names(test_woe) <- names

#3  Resolving "Multicollinearity" problem----

solve_multicollinearity <- function(encoded_data, target){
  features <- encoded_data %>% select(-all_of(target)) %>% names()
  
  f <- as.formula(paste(target, paste(features, collapse = "+"), sep = "~"))
  glm <- glm(f, encoded_data = encoded_data, family ="binomial")
  
  coef_na <- attributes(alias(glm)$Complete)$dimnames [[1]]
  features <- features [! features %in% coef_na]
  f <- as.formula(paste(target, paste(features, collapse = ), sep= ""))
  glm <- glm(f, data = data, family = "binomial")
  
  while(glm %>% vif() %>% arrange(desc(gvif)) %>% .[1,2] >= 2){
  afterVIF <- glm %>% vif( ) %>% arrange (desc(gvif)) %>% pull(variable) %>% .[-1]
  f <- as.formula(paste(target, paste(afterVIF, collapse = " + "), sep = " ~ "))
  glm <- glm(f, data = data, family = "binomial")
  }
  
  return(glm %>% vif() %>% pull(variable))
}


cor_matrix <- cor(train_woe[, -1])  # Excluding the target variable

# Finding highly correlated variables
highly_correlated <- findCorrelation(cor_matrix, cutoff = 0.8)

# Removing highly correlated variables
train_woe_no_collinearity <- train_woe[, -highly_correlated]

features <- colnames(train_woe_no_collinearity)[-1]

# Building GLM (Generalized Linear Model) with Cross Validation ----

h2o.init()

train_h2o <- train_woe %>% select(target, all_of(features)) %>% as.h2o()
test_h2o <- test_woe %>% select(target, all_of(features)) %>% as.h2o()

model <- h2o.glm(
  x = features, y =target, family = "binomial",
  training_frame = train_h2o, validation_frame = test_h2o,
  nfolds = 10, seed = 123, remove_collinear_columns = T,
  balance_classes = T, lambda = 0, compute_p_values = T)

# Significance level ----

while (model@model$coefficients_table %>%
       as.data.frame() %>%
       select(names,p_value) %>%
       mutate (p_value = round(p_value, 3)) %>%
       .[-1,] %>%
       arrange(desc(p_value)) %>%
       .[1,2] >= 0.05){
  model@model$coefficients_table %>%
    as.data.frame() %>%
    select (names, p_value) %>%
    mutate (p_value = round(p_value, 3)) %>%
    filter(!is.nan(p_value)) %>%
    . [-1,] %>%
    arrange(desc(p_value)) %>%
    .[1,1] -> V
  features <- features [features !=v]
  
  train_h20 <- train_woe %>% select(target, all_of(features)) %>% as.h2o()
  test_h20 <- test_woe %>% select(target, all_of(features)) %>% as.h2o()
  
  model <- h2o.glm(
    x = features, y = target, family = "binomial",
    training_frame = train_h2o, validation_frame= test_h2o,
    nfolds = 10, seed = 123, remove_collinear_columns= T,
    balance_classes = T, lambda = 0, compute_p_values = T)
}
model@model$coefficients_table %>%
  as.data.frame() %>%
  select(names, p_value) %>%
  mutate(p_value = round(p_value, 3))

model@model$coefficients %>%
  as.data.frame() %>%
  mutate (names = rownames (model@model$coefficients %>% as.data.frame())) %>%
  `colnames<-`(c("coefficients", "names")) %>%
  select(names, coefficients) %>%
  as_tibble()

h2o.varimp(model) %>% as.data.frame() %>%
  filter (percentage != 0) %>%
  select(variable, percentage) %>%
  hchart("pie", hcaes(x = variable, y = percentage)) %>%
  hc_colors(colors = "orange") %>%
  hc_xAxis (visible=T) %>%

# Prediction ----  
  
pred <-  model %>% h2o.predict(test_h2o) %>% 
  as.data.frame() %>% select(p1,predict)

# Optimal treshold

pred[pred$predict ==0, "p1"] %>% max()
pred[pred$predict ==1, "p1"] %>% min()

modelMh2o.performance(test_h2o) %>% 
  h2o.find_threshold_by_max_metric("f1")

#4 Showing performance of model ----

# Confusion matrice

actuals <- dt_list$test %>% pull(target)
predictions <- pred$predict

actuals %>% table()

cm <- table(actuals, predictions)

tp <- cm[2,2]
tn <- cm[1,1]
fp <- cm[1,2]
tn <- cm[2,1]

precision <-  tp/(tp+fp)
recall_sensitivity <- tp/(tp+fn)
specificity <- tn/(tn+fn)
accuracy <- (tp+tn)/(tp+tn+fp+fn)
f1_score <- 2*precision*recall_sensitivity/(precision+recall_sensitivity)
balanced_accuracy <- (recall_sensitivity+specificity)/2

tibble(precision,recall_sensitivity, specificity,
       accuracy, f1_score, balanced_accuracy)

# AUC and ROC

model %>% 
  h2o.performance(test_h2o) %>% 
  h2o.metric() %>% 
  select(treshold, precision, recall, tpr, fpr) %>% 
  add_columnn(random_tpr = runif(nrow(.), min = 0.001, max = 1)) %>% 
  mutate(random_fpr = random_tpr) %>% 
  arrange(random_tpr = random_fpr)-> metrics

model %>% 
  h2o.performance(test_h2o) %>% 
  h2o.auc() %>% round(2)-> auc

highchart() %>%
  hc_add_series (metrics, "scatter", hcaes(y=tpr,x=fpr), color='green', name='TPR') %>%
  hc_add_series (metrics, "line", hcaes(y=random_tpr, x=random_fpr), color='red', name='Təsadüfi təxmin') %>%
  hc_add_annotation(
    labels = list(
     point = list(xAxis=0, yAxis=0, x=0.3, y=-0.6),
     text = glue('AUC = {enexpr(auc)}'))
 ) %>%
 hc_title(text = "ROC əyrisi") %>%
 hc_subtitle(text = "Model təsadüfi təxmindən daha yaxşı performans göstərir")

#  Checking "Overfitting" or "Underfitting"

model %>% 
  h2o.auc(train = T,
          valid =T,
          xval =T) %>% 
  as_tibble() %>% 
  round(2) %>% 
  mutate(data =c("train", "test", "cross_val")) %>% 
  mutate(gini =2*value-1) %>% 
  select(data, auc = value, gini)
